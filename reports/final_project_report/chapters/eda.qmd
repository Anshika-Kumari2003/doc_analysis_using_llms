# Pre-Processing and Exploratory Data Analysis

## Dataset Collection

This project utilizes a comprehensive collection of financial documents and reports from multiple companies, providing a robust dataset for financial analysis and document understanding. The dataset consists of SEC filings (10-K reports) and annual reports from eight major companies across diverse industries.

### Data Sources

**Dataset Composition**

The dataset includes financial documents from the following companies:

- **Technology Sector**:
  - Amazon (2022 10-K report)
  - Apple (2021 10-K report)
  - NVIDIA (10-K report)
- **Automotive Industry**:
  - Tesla (10-K report)
- **Defense and Aerospace**:
  - Lockheed Martin (10-K report)
- **Industrial and Energy**:
  - EnerSys (2023 and 2017 10-K reports)
  - TransDigm (2022 10-K report)
  - Advent Technologies (2022 10-K report)

**Document Characteristics**

- **Source**: SEC EDGAR database and official company reports
- **Format**: PDF documents containing mixed content types
- **Structure**: Multi-page documents with financial statements, business descriptions, and regulatory disclosures
- **Content Types**: Structured numerical data in tables and unstructured narrative text
- **Size**: Documents range from moderate to large-scale comprehensive filings

### Selection Criteria

The companies were selected to provide:

- **Industry Diversity**: Coverage across technology, automotive, defense, and industrial sectors
- **Company Size Variation**: Mix of large multinational corporations and specialized companies
- **Document Complexity**: Varying levels of financial reporting complexity
- **Data Quality**: Complete, well-formatted documents suitable for text extraction

## Data Pre-processing Pipeline

The pre-processing pipeline transforms raw PDF documents into structured, searchable content through multiple stages of processing and analysis.

### Stage 1: PDF Document Processing

**Text Extraction**

The system uses pdfplumber library for robust PDF text extraction:

- **Text Content**: Extracts narrative text while preserving document structure
- **Table Extraction**: Identifies and extracts tabular data with structure preservation
- **Page Handling**: Maintains page boundaries and numbering for reference
- **Format Preservation**: Retains important formatting elements and document hierarchy

**Content Type Identification**

During extraction, the system categorizes content into:

- **Text Passages**: Narrative sections including business descriptions and analysis
- **Financial Tables**: Structured numerical data and financial statements
- **Mixed Content**: Sections combining text with embedded tables and references

### Stage 2: Text Processing and Normalization

**Text Cleaning Process**

The extracted text undergoes comprehensive cleaning and normalization:

- **Whitespace Normalization**: Removes excessive whitespace while preserving document structure
- **Character Encoding**: Standardizes character encoding for consistent processing
- **Special Character Handling**: Properly processes financial symbols, mathematical notation, and currency indicators
- **Document Structure Preservation**: Maintains page markers, section headers, and hierarchical organization

**Quality Assurance**

- **Missing Content Handling**: Implements graceful handling of missing or corrupted text sections
- **Table Structure Maintenance**: Preserves table formatting and numerical data integrity
- **Reference Preservation**: Maintains internal document references and cross-references
- **Error Recovery**: Provides fallback mechanisms for processing issues

### Stage 3: Document Chunking Strategy

**Chunking Implementation**

The system implements a recursive text splitting approach with the following specifications:

- **Chunk Size**: 700 characters per chunk, optimized for semantic coherence
- **Overlap**: 150 characters between adjacent chunks to preserve context
- **Splitting Method**: Recursive character splitting that respects natural text boundaries
- **Table Handling**: Special processing for financial tables to maintain data integrity

**Chunking Features**

- **Context Preservation**: Overlap ensures continuity of meaning across chunk boundaries
- **Table Integrity**: Complete tables are processed as single units when possible
- **Page Reference Maintenance**: Each chunk retains reference to its source page and document
- **Flexible Processing**: Multiple chunking strategies for different content types

### Stage 4: Image and Visual Content Processing

**Image Extraction**

The system extracts visual content from PDF documents:

- **Page Images**: Extracts complete page images at 150 DPI resolution
- **Storage Organization**: Creates organized directory structure for image storage
- **Image Mapping**: Develops JSON-based mapping between images and document sections
- **Citation Support**: Enables visual citations linking text to specific page images

**Visual Content Management**

- **Efficient Storage**: Optimized image storage with systematic naming conventions
- **Quick Retrieval**: Indexed system for fast image access during analysis
- **Quality Preservation**: Maintains image quality sufficient for reference and analysis

## Exploratory Data Analysis

### Document Content Analysis

**Content Distribution Assessment**

The exploratory analysis examines the composition and structure of the processed documents:

- **Document Count**: 8 companies with multiple filing types
- **Content Variety**: Mix of narrative text, financial tables, and regulatory disclosures
- **Processing Coverage**: Complete document processing with full text extraction
- **Chunk Generation**: Documents segmented into manageable chunks for analysis

**Content Type Distribution**

The system processes and categorizes content into:

- **Text Content**: Narrative sections describing business operations and strategies
- **Tabular Data**: Financial statements and numerical disclosures
- **Mixed Sections**: Areas combining descriptive text with embedded financial data
- **Regulatory Content**: Standardized sections addressing SEC reporting requirements

### Document Processing Quality Assessment

**Extraction Effectiveness**

Evaluation of the document processing pipeline:

- **Completeness**: Text extraction from PDF documents
- **Structure Preservation**: Maintenance of document hierarchy
- **Table Handling**: Extraction and formatting of financial tables
- **Error Handling**: Basic error handling for processing issues

**Processing Consistency**

- **Cross-Document Processing**: Consistent processing approach across documents
- **Format Handling**: Processing of various PDF formats
- **Content Preservation**: Basic content preservation through processing pipeline

### Semantic Analysis Implementation

**Embedding Generation**

The system implements semantic analysis using advanced natural language processing:

- **Model**: Sentence Transformers using all-mpnet-base-v2 architecture
- **Dimensionality**: 768-dimensional embeddings for each text chunk
- **Processing**: Batch processing of document chunks for efficiency
- **Coverage**: Complete embedding generation for all processed text chunks

**Embedding Characteristics**

- **Semantic Representation**: High-quality semantic vectors capturing meaning and context
- **Search Capability**: Enables similarity-based search and retrieval
- **Vector Storage**: Efficient storage and indexing of generated embeddings
- **Retrieval Optimization**: Optimized for fast similarity searches

### Search and Retrieval System

**Search Configuration**

The implemented search system provides configurable retrieval capabilities:

- **Top-k Retrieval**: Configurable number of results (default: 5)
- **Score Threshold**: Relevance threshold for result filtering (default: 0.4)
- **Result Limitation**: Maximum results per query (default: 3)
- **Similarity Metric**: Cosine similarity for semantic matching

**Search Features**

- **Semantic Search**: Meaning-based search beyond keyword matching
- **Relevance Scoring**: Quantitative relevance scores for search results
- **Document Grouping**: Results organized by source document and page
- **Context Preservation**: Retrieved chunks maintain context from surrounding content

### Visualization and User Interface

**Document Display System**

The system provides basic visualization capabilities:

- **Page Image Display**: Display of document page images
- **Table Formatting**: Basic display of financial tables
- **Search Result Presentation**: Display of search results with relevance scores
- **Citation System**: Basic links between search results and source pages

**Interface Components**

- **Document Navigation**: Basic page navigation
- **Search Interface**: Search functionality with result display
- **Content Organization**: Basic content type organization
- **Result Filtering**: Basic result filtering

### Processing Performance Analysis

**Pipeline Efficiency**

Basic analysis of the document processing pipeline:

- **Document Processing**: Basic document processing functionality
- **Text Extraction**: Text and table extraction capabilities
- **Chunk Generation**: Chunking process implementation
- **Embedding Generation**: Basic embedding creation process

**System Performance**

- **Basic Memory Usage**: Resource utilization during processing
- **Storage Requirements**: Space needed for processed documents
- **Search Response**: Basic search operation performance
- **Batch Processing**: Basic multi-document processing

### Data Quality and Integrity

**Content Quality Assessment**

Basic evaluation of processed content:

- **Text Extraction**: Basic text extraction functionality
- **Table Structure**: Basic table formatting preservation
- **Context Maintenance**: Basic context preservation through chunking
- **Reference Handling**: Basic reference preservation

**Error Analysis**

- **Processing Issues**: Basic error handling
- **Content Processing**: Basic content processing functionality
- **Format Handling**: Basic format processing
- **Recovery Process**: Basic error recovery mechanisms

### Chunking Strategy Evaluation

**Chunking Effectiveness Analysis**

Basic assessment of the implemented chunking strategy:

- **Semantic Coherence**: Basic semantic chunking implementation
- **Context Preservation**: Basic context maintenance across chunks
- **Size Management**: Implementation of 700-character chunk size
- **Overlap Implementation**: 150-character overlap strategy

**Chunking Performance**

- **Basic Processing**: Chunk processing functionality
- **Resource Usage**: Basic resource requirements
- **Storage Management**: Basic storage requirements
- **Retrieval Functionality**: Basic search and retrieval implementation

### Vector Database Performance

**Embedding Storage and Retrieval**

Basic analysis of the vector database implementation:

- **Storage Implementation**: Basic embedding storage
- **Query Functionality**: Basic similarity search implementation
- **Index Management**: Basic vector indexing
- **System Scalability**: Basic multi-document handling

**Search Quality**

- **Basic Retrieval**: Implementation of semantic search
- **Response Time**: Basic search operation speed
- **Result Handling**: Basic result processing
- **System Operation**: Basic system functionality