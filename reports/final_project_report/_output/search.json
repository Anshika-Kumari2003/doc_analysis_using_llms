[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#preface-1",
    "href": "index.html#preface-1",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Preface",
    "text": "Preface\nThis project was undertaken as part of the internship program at the Sabudh Foundation, with the aim of applying theoretical concepts to real-world problem-solving using modern AI tools and techniques.\nThe project was allotted to our team to explore how large language models (LLMs), speech recognition systems, and data interaction techniques can be used to simplify access to information across various data formats—documents, videos, and structured spreadsheets. Under the valuable guidance of the Sabudh mentorship team, we worked collaboratively to build a unified solution that demonstrates the power of Retrieval-Augmented Generation (RAG), YouTube transcript analysis, and natural language querying over Excel data.\nThroughout this journey, we gained practical exposure to tools such as LangChain, OpenAI Whisper, vector databases, SQL agents, and lightweight LLMs like Phi-3 Mini. We also learned how to design intuitive interfaces using Gradio and Jupyter widgets to make our system accessible and user-friendly.\nWe would like to express our heartfelt gratitude to the Sabudh Foundation for this enriching opportunity and continuous support. We are especially thankful to our project guide, Mr. Bhupender Sharma, for his expert mentorship, insightful feedback, and encouragement at every stage of the project. His guidance was instrumental in shaping the outcome of this work.\nThis experience has significantly enhanced our technical capabilities and understanding of AI-driven systems and will remain a valuable milestone in our academic and professional journey.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Overview",
    "text": "Overview\nIn today’s information-rich world, users often struggle to extract insights from documents, videos, or spreadsheets without specialized tools or technical skills. This project bridges that gap through an AI-powered system that allows users to “talk” to their data—regardless of its format.\nThe system is built around three intelligent agents:\n\nA A Multi-Agent Assistant that automatically analyzes user queries and routes them to the most suitable agent—whether it involves company-specific data, video searches, or web-based information retrieval—creating a unified conversational interface.\nA Document Agent that reads and answers questions from uploaded PDFs or text files using retrieval-augmented generation.\nA YouTube Agent that listens to videos, summarizes key points, and provides answers based on transcripts.\nA SQL Agent that converts plain English queries into SQL to interpret Excel sheets effortlessly.\n\nBy combining the strengths of language models, semantic search, and speech recognition, this solution offers a unified, conversational way to analyze diverse types of content—no coding required.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#objectives-of-project",
    "href": "index.html#objectives-of-project",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Objectives of Project",
    "text": "Objectives of Project\nThe primary goal of this project is to develop an intelligent, multi-modal AI system capable of understanding and interacting with diverse types of data using natural language. The specific objectives are:\n\nEnhance Information Retrieval from Documents:\n\nImplement a Retrieval-Augmented Generation (RAG) pipeline to answer user queries based on uploaded PDFs or text files.\nUse semantic chunking and vector embeddings to ensure relevant and accurate responses.\n\nSimplify Video Content Understanding:\n\nUse Whisper to transcribe audio from YouTube videos.\nGenerate summaries and enable question-answering on the transcribed content to help users extract key insights quickly.\n\nEnable Natural Language Interaction with Tabular Data:\n\nAccept Excel file uploads and parse structured data.\nConvert user questions into SQL queries using text-to-SQL methods, and display results clearly.\n\nProvide a Unified, User-Friendly Interface:\n\nDesign modular and accessible interfaces (e.g., via Gradio or Jupyter Widgets) to support smooth interaction with all three modules.\n\nDemonstrate Real-World Applicability of LLMs:\n\nShowcase how lightweight language models (like Phi-3 Mini) can handle diverse tasks across domains with minimal user effort.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#dataset-collection",
    "href": "index.html#dataset-collection",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Dataset Collection",
    "text": "Dataset Collection\nThis project utilizes a comprehensive collection of financial documents and reports from multiple companies, providing a robust dataset for financial analysis and document understanding. The dataset consists of SEC filings (10-K reports) and annual reports from eight major companies across diverse industries.\n\nData Sources\nDataset Composition\nThe dataset includes financial documents from the following companies:\n\nTechnology Sector:\n\nAmazon (2022 10-K report)\nApple (2021 10-K report)\nNVIDIA (10-K report)\n\nAutomotive Industry:\n\nTesla (10-K report)\n\nDefense and Aerospace:\n\nLockheed Martin (10-K report)\n\nIndustrial and Energy:\n\nEnerSys (2023 and 2017 10-K reports)\nTransDigm (2022 10-K report)\nAdvent Technologies (2022 10-K report)\n\n\nDocument Characteristics\n\nSource: SEC EDGAR database and official company reports\nFormat: PDF documents containing mixed content types\nStructure: Multi-page documents with financial statements, business descriptions, and regulatory disclosures\nContent Types: Structured numerical data in tables and unstructured narrative text\nSize: Documents range from moderate to large-scale comprehensive filings\n\n\n\nSelection Criteria\nThe companies were selected to provide:\n\nIndustry Diversity: Coverage across technology, automotive, defense, and industrial sectors\nCompany Size Variation: Mix of large multinational corporations and specialized companies\nDocument Complexity: Varying levels of financial reporting complexity\nData Quality: Complete, well-formatted documents suitable for text extraction",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#data-pre-processing-pipeline",
    "href": "index.html#data-pre-processing-pipeline",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Data Pre-processing Pipeline",
    "text": "Data Pre-processing Pipeline\nThe pre-processing pipeline transforms raw PDF documents into structured, searchable content through multiple stages of processing and analysis.\n\nStage 1: PDF Document Processing\nText Extraction\nThe system uses pdfplumber library for robust PDF text extraction:\n\nText Content: Extracts narrative text while preserving document structure\nTable Extraction: Identifies and extracts tabular data with structure preservation\nPage Handling: Maintains page boundaries and numbering for reference\nFormat Preservation: Retains important formatting elements and document hierarchy\n\nContent Type Identification\nDuring extraction, the system categorizes content into:\n\nText Passages: Narrative sections including business descriptions and analysis\nFinancial Tables: Structured numerical data and financial statements\nMixed Content: Sections combining text with embedded tables and references\n\n\n\nStage 2: Text Processing and Normalization\nText Cleaning Process\nThe extracted text undergoes comprehensive cleaning and normalization:\n\nWhitespace Normalization: Removes excessive whitespace while preserving document structure\nCharacter Encoding: Standardizes character encoding for consistent processing\nSpecial Character Handling: Properly processes financial symbols, mathematical notation, and currency indicators\nDocument Structure Preservation: Maintains page markers, section headers, and hierarchical organization\n\nQuality Assurance\n\nMissing Content Handling: Implements graceful handling of missing or corrupted text sections\nTable Structure Maintenance: Preserves table formatting and numerical data integrity\nReference Preservation: Maintains internal document references and cross-references\nError Recovery: Provides fallback mechanisms for processing issues\n\n\n\nStage 3: Document Chunking Strategy\nChunking Implementation\nThe system implements a recursive text splitting approach with the following specifications:\n\nChunk Size: 700 characters per chunk, optimized for semantic coherence\nOverlap: 150 characters between adjacent chunks to preserve context\nSplitting Method: Recursive character splitting that respects natural text boundaries\nTable Handling: Special processing for financial tables to maintain data integrity\n\nChunking Features\n\nContext Preservation: Overlap ensures continuity of meaning across chunk boundaries\nTable Integrity: Complete tables are processed as single units when possible\nPage Reference Maintenance: Each chunk retains reference to its source page and document\nFlexible Processing: Multiple chunking strategies for different content types\n\n\n\nStage 4: Image and Visual Content Processing\nImage Extraction\nThe system extracts visual content from PDF documents:\n\nPage Images: Extracts complete page images at 150 DPI resolution\nStorage Organization: Creates organized directory structure for image storage\nImage Mapping: Develops JSON-based mapping between images and document sections\nCitation Support: Enables visual citations linking text to specific page images\n\nVisual Content Management\n\nEfficient Storage: Optimized image storage with systematic naming conventions\nQuick Retrieval: Indexed system for fast image access during analysis\nQuality Preservation: Maintains image quality sufficient for reference and analysis",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#exploratory-data-analysis",
    "href": "index.html#exploratory-data-analysis",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nDocument Content Analysis\nContent Distribution Assessment\nThe exploratory analysis examines the composition and structure of the processed documents:\n\nDocument Count: 8 companies with multiple filing types\nContent Variety: Mix of narrative text, financial tables, and regulatory disclosures\nProcessing Coverage: Complete document processing with full text extraction\nChunk Generation: Documents segmented into manageable chunks for analysis\n\nContent Type Distribution\nThe system processes and categorizes content into:\n\nText Content: Narrative sections describing business operations and strategies\nTabular Data: Financial statements and numerical disclosures\nMixed Sections: Areas combining descriptive text with embedded financial data\nRegulatory Content: Standardized sections addressing SEC reporting requirements\n\n\n\nDocument Processing Quality Assessment\nExtraction Effectiveness\nEvaluation of the document processing pipeline:\n\nCompleteness: Text extraction from PDF documents\nStructure Preservation: Maintenance of document hierarchy\nTable Handling: Extraction and formatting of financial tables\nError Handling: Basic error handling for processing issues\n\nProcessing Consistency\n\nCross-Document Processing: Consistent processing approach across documents\nFormat Handling: Processing of various PDF formats\nContent Preservation: Basic content preservation through processing pipeline\n\n\n\nSemantic Analysis Implementation\nEmbedding Generation\nThe system implements semantic analysis using advanced natural language processing:\n\nModel: Sentence Transformers using all-mpnet-base-v2 architecture\nDimensionality: 768-dimensional embeddings for each text chunk\nProcessing: Batch processing of document chunks for efficiency\nCoverage: Complete embedding generation for all processed text chunks\n\nEmbedding Characteristics\n\nSemantic Representation: High-quality semantic vectors capturing meaning and context\nSearch Capability: Enables similarity-based search and retrieval\nVector Storage: Efficient storage and indexing of generated embeddings\nRetrieval Optimization: Optimized for fast similarity searches\n\n\n\nSearch and Retrieval System\nSearch Configuration\nThe implemented search system provides configurable retrieval capabilities:\n\nTop-k Retrieval: Configurable number of results (default: 5)\nScore Threshold: Relevance threshold for result filtering (default: 0.4)\nResult Limitation: Maximum results per query (default: 3)\nSimilarity Metric: Cosine similarity for semantic matching\n\nSearch Features\n\nSemantic Search: Meaning-based search beyond keyword matching\nRelevance Scoring: Quantitative relevance scores for search results\nDocument Grouping: Results organized by source document and page\nContext Preservation: Retrieved chunks maintain context from surrounding content\n\n\n\nVisualization and User Interface\nDocument Display System\nThe system provides basic visualization capabilities:\n\nPage Image Display: Display of document page images\nTable Formatting: Basic display of financial tables\nSearch Result Presentation: Display of search results with relevance scores\nCitation System: Basic links between search results and source pages\n\nInterface Components\n\nDocument Navigation: Basic page navigation\nSearch Interface: Search functionality with result display\nContent Organization: Basic content type organization\nResult Filtering: Basic result filtering\n\n\n\nProcessing Performance Analysis\nPipeline Efficiency\nBasic analysis of the document processing pipeline:\n\nDocument Processing: Basic document processing functionality\nText Extraction: Text and table extraction capabilities\nChunk Generation: Chunking process implementation\nEmbedding Generation: Basic embedding creation process\n\nSystem Performance\n\nBasic Memory Usage: Resource utilization during processing\nStorage Requirements: Space needed for processed documents\nSearch Response: Basic search operation performance\nBatch Processing: Basic multi-document processing\n\n\n\nData Quality and Integrity\nContent Quality Assessment\nBasic evaluation of processed content:\n\nText Extraction: Basic text extraction functionality\nTable Structure: Basic table formatting preservation\nContext Maintenance: Basic context preservation through chunking\nReference Handling: Basic reference preservation\n\nError Analysis\n\nProcessing Issues: Basic error handling\nContent Processing: Basic content processing functionality\nFormat Handling: Basic format processing\nRecovery Process: Basic error recovery mechanisms\n\n\n\nChunking Strategy Evaluation\nChunking Effectiveness Analysis\nBasic assessment of the implemented chunking strategy:\n\nSemantic Coherence: Basic semantic chunking implementation\nContext Preservation: Basic context maintenance across chunks\nSize Management: Implementation of 700-character chunk size\nOverlap Implementation: 150-character overlap strategy\n\nChunking Performance\n\nBasic Processing: Chunk processing functionality\nResource Usage: Basic resource requirements\nStorage Management: Basic storage requirements\nRetrieval Functionality: Basic search and retrieval implementation\n\n\n\nVector Database Performance\nEmbedding Storage and Retrieval\nBasic analysis of the vector database implementation:\n\nStorage Implementation: Basic embedding storage\nQuery Functionality: Basic similarity search implementation\nIndex Management: Basic vector indexing\nSystem Scalability: Basic multi-document handling\n\nSearch Quality\n\nBasic Retrieval: Implementation of semantic search\nResponse Time: Basic search operation speed\nResult Handling: Basic result processing\nSystem Operation: Basic system functionality",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#introduction-to-python-for-machine-learning",
    "href": "index.html#introduction-to-python-for-machine-learning",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Introduction to Python for Machine Learning",
    "text": "Introduction to Python for Machine Learning\nThis project implements a comprehensive Retrieval-Augmented Generation (RAG) system using Python, designed to handle multiple data sources including financial documents, YouTube transcripts, and structured CSV data. The system leverages large language models (LLMs) through Ollama, vector databases via Pinecone, and modern web interfaces through Gradio to create an intelligent multi-agent assistant.\nThe core methodology combines traditional information retrieval techniques with modern transformer-based language models to provide accurate, contextual responses across different domains of knowledge.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#system-architecture-overview",
    "href": "index.html#system-architecture-overview",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "System Architecture Overview",
    "text": "System Architecture Overview\n\n\n\nRAG Workflow Diagram\n\n\nThe RAG workflow diagram above illustrates the fundamental processing pipeline of our system. The workflow demonstrates the complete data flow from document ingestion through response generation:\n\nPDF Parsing: Documents are processed and parsed into manageable chunks with page preservation\nEncoding: Text chunks are converted into embeddings using the all-mpnet-base-v2 model\nVector Database Indexing: Embeddings are stored in Pinecone with namespace-based organization\nQuery Processing: User queries are encoded and matched against stored documents\nSimilarity Search: Most relevant document chunks are retrieved with page citations\nResponse Generation: The Phi-3 model generates contextual responses\nFinal Output: Users receive comprehensive answers with proper citations and visual references\n\n\n\n\nMulti-Modal System Architecture\n\n\nThe multi-modal system architecture diagram showcases the integration of various specialized workflows within our AI assistant platform:\n\nDocument QA Workflow: Handles PDF processing, embedding generation, and semantic search\nYouTube QA Workflow: Manages video transcript extraction and analysis\nSQL Agent Workflow: Processes CSV data and enables natural language database queries\nAI Assistant Integration Hub: Coordinates all workflows through intelligent routing",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#platform-and-machine-configurations-used",
    "href": "index.html#platform-and-machine-configurations-used",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Platform and Machine Configurations Used",
    "text": "Platform and Machine Configurations Used\n\nDevelopment Environment\n\nPrimary Platform: Local development environment with Docker containerization support\nAlternative Platforms: Compatible with Google Colab, Kaggle notebooks, and cloud instances\nOperating System: Cross-platform support (Windows, macOS, Linux) with WSL compatibility\n\n\n\nMachine Configuration Requirements\n\nMinimum Requirements\n\n\n\n\n\n\n\nComponent\nSpecification\n\n\n\n\nCPU\n4-core processor (Intel i5 or AMD Ryzen 5 equivalent)\n\n\nRAM\n8GB (16GB recommended for optimal performance)\n\n\nStorage\n20GB free space for models and vector databases\n\n\nGPU\nOptional but recommended (NVIDIA GTX 1060 or better for faster inference)\n\n\n\n\n\nRecommended Configuration\n\n\n\nComponent\nSpecification\n\n\n\n\nCPU\n8-core processor (Intel i7/i9 or AMD Ryzen 7/9)\n\n\nRAM\n32GB for handling large document collections\n\n\nStorage\nSSD with 50GB+ free space\n\n\nGPU\nNVIDIA RTX 3070 or better with 8GB+ VRAM\n\n\n\n\n\n\nSoftware Dependencies\n\nPython Version: 3.8+\nKey Libraries:\n\n\nLangChain for LLM orchestration\nPinecone for vector database operations\nGradio for web interface\nOllama for local LLM serving\nYouTube Transcript API for video processing",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#data-architecture-and-sources",
    "href": "index.html#data-architecture-and-sources",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Data Architecture and Sources",
    "text": "Data Architecture and Sources\n\nData Source Classification\nThe system processes three primary data types:\n\nStructured Documents: SEC filings (10-K forms) from companies like EnerSys, Apple, and NVIDIA\nUnstructured Video Content: YouTube transcripts and metadata\nTabular Data: CSV files for SQL-based querying\n\n\n\nData Preprocessing Pipeline\n\nDocument Processing\nRaw PDF → Text Extraction → Chunking (700/150) → Embedding → Vector Storage \n\n\nVideo Content Processing\nYouTube URL → Transcript Extraction → Text Preprocessing → Context Storage \n\n\nStructured Data Processing\nCSV Upload → Schema Detection → SQLite Database → Query Interface",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#model-planning-and-architecture",
    "href": "index.html#model-planning-and-architecture",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Model Planning and Architecture",
    "text": "Model Planning and Architecture\n\nMulti-Agent System Design\nThe system implements a router-based multi-agent architecture with the following specialized agents:\n\n1. Document QA Agents (Company-Specific)\n\nEnerSys Agent: Specialized in battery and energy storage company data\nApple Agent: Focused on consumer electronics and technology financials\nNVIDIA Agent: Expert in semiconductor and AI hardware information\n\n\n\n2. Content Discovery Agent\n\nYouTube Search Agent: Retrieves and analyzes video content based on queries\n\n\n\n3. General Knowledge Agent\n\nWeb Search Agent: Handles general queries using Tavily API for real-time information\n\n\n\n4. Structured Data Agent\n\nSQL Agent: Processes natural language queries on tabular data\n\n\n\n\nModel Selection Strategy\n\nPrimary LLM: Ollama with Phi-3 Mini\n# Model Configuration \nOLLAMA_MODEL = \"phi3:mini\" \nOLLAMA_API_BASE = \"http://localhost:11434/api\" \n# Model Parameters \ntemperature = 0.1  # Low temperature for factual accuracy \ntop_p = 0.9       # Nucleus sampling for diversity \nnum_predict = 512  # Token limit for responses \n\n\nEmbedding Model: Sentence Transformers\n\nModel: all-mpnet-base-v2 for semantic similarity\nDimension: 768 dimensions\nPurpose: Converting text chunks into dense vector representations",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#system-implementation",
    "href": "index.html#system-implementation",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "System Implementation",
    "text": "System Implementation\n\nVector Database Configuration\n\nPinecone Setup\n# Index Configuration \nINDEX_NAME = \"document-analysis\" \nEMBEDDING_DIMENSION = 768 \nMETRIC = \"cosine\"  # Cosine similarity for semantic search \n\n\nRetrieval Strategy\n\nTop-K Retrieval: Returns top 5 most relevant chunks\nNamespace Filtering: Company-specific document organization\nPage Preservation: Maintains page numbers for citations\n\n\n\n\nAgent Routing Logic\n\nLLM-Based Routing\nThe system uses the primary LLM to determine which specialized agent should handle each query:\ndef llm_route_question(question: str, chat_history: list = None) -&gt; str: \n\"\"\"\nIntelligent routing based on: \n1. Query content analysis \n2. Named entity recognition \n3. Context from chat history \n4. Domain-specific keywords \n\"\"\" \n\n\nRouting Decision Matrix\n\n\n\nQuery Type\nTarget Agent\nConfidence Threshold\n\n\n\n\nCompany-specific financial\nCompany Agent\n0.8+\n\n\nVideo/Tutorial request\nYouTube Agent\n0.9+\n\n\nGeneral knowledge\nWeb Search Agent\n0.6+\n\n\nData analysis\nSQL Agent\n0.7+\n\n\n\n\n\n\nDocument Processing Implementation\n\nChunking Strategy\n\nChunk Size: 700 tokens per chunk\nOverlap: 150 tokens between chunks\nStrategy: Recursive chunking with page preservation\nTable Handling: Special processing for tabular data\n\n\n\nImage Mapping System\n\nPage Images: Automatic extraction and storage\nCitation System: JSON-based image mapping\nVisual References: Gallery display of cited pages\n\n\n\n\nResponse Generation\n\nPrompt Engineering\nprompt_template = \"\"\" \nBased on the following context from {company} {document_type},  \nanswer the question correctly and concisely. \nContext: {retrieved_context} \nQuestion: {user_question} \nChat History: {conversation_history} \nAnswer with specific page references where applicable: \n\"\"\" \n\n\nParameter Optimization\n\nTemperature Control: 0.1 for factual accuracy\nLength Control: 512 token limit for responses\nCitation Integration: Automatic page number and source attribution\n\n\n\n\nSQL Agent Implementation\n\nNatural Language to SQL Conversion\n\nColumn Matching: Fuzzy matching for column names with enhanced error handling\nQuery Generation: Two-tier approach with Ollama and fallback mechanisms\nSchema Detection: Automatic column type inference from CSV data\nQuery Validation: Robust error handling with informative messages\n\n\n\nSQL Generation Features\n# Enhanced SQL generation with better column matching\ndef generate_sql_with_ollama(query, table_name, columns, model=OLLAMA_MODEL):\n    # Create a more detailed prompt with column information\n    column_info = \"\\n\".join([f\"- {col}\" for col in columns])\n    \n    prompt = f\"\"\"\nYou are an expert SQL query generator. Given a natural language question and database schema, generate a precise SQL query.\n\nDatabase Information:\n- Table name: {table_name}\n- Available columns:\n{column_info}\n\nIMPORTANT RULES:\n1. Generate ONLY the SQL query, no explanations or markdown\n2. Use proper SQL syntax for SQLite\n3. Column names must EXACTLY match the available columns listed above\n4. Always use LIMIT clause for SELECT queries (default LIMIT 10)\n5. For aggregation queries (COUNT, SUM, AVG, etc.), don't use LIMIT unless grouping\n6. Use LIKE operator with % wildcards for text searches\n7. If a column name in the question doesn't exist, find the closest matching column from the list above\n\"\"\"\n\n\n\nYouTube QA Implementation\n\nTranscript Processing\n\nBackground Fetching: Asynchronous transcript retrieval\nCaching System: Persistent storage of transcripts in JSON format\nError Handling: Robust error management for failed transcript fetches\nContext Management: Efficient handling of long transcripts\n\n\n\nQA Features\n# Answer generation with context management\ndef answer_question(question, url, model):\n    video_id = extract_video_id(url)\n    if video_id not in video_context:\n        return \"Transcript not ready yet.\"\n    context = video_context[video_id]\n    if context.startswith(\"Error\"):\n        return context\n    prompt = f\"\"\"Answer the following question based on this YouTube video transcript:\\n\n    Transcript:\\n{context[:4000]}\\n\n    Question: {question}\n    \"\"\"\n\n\nVideo Analysis Capabilities\n\nTranscript Summarization: AI-powered video content summarization\nQuestion Answering: Context-aware responses based on video content\nModel Selection: Support for multiple Ollama models\nBackground Processing: Non-blocking transcript retrieval",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#final-system-architecture",
    "href": "index.html#final-system-architecture",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Final System Architecture",
    "text": "Final System Architecture\n\nComponent Integration\n\nWeb Interface (Gradio)\n\nMulti-tab Interface: Separate tabs for different functionalities\nReal-time Updates: Live status updates during processing\nInteractive Elements: File uploads, dropdowns, and chat interfaces\n\n\n\nBackend Services\n\nOllama Server: Local LLM serving with API endpoints\nPinecone Cloud: Managed vector database service\nSQLite Database: Local structured data processing\n\n\n\nData Flow Architecture\nUser Query → Router Agent → Specialized Agent → Retrieval → LLM → Response \n↓ \nContext Management → Citation Generation → Response Formatting → UI Display \n\n\n\nFuture Development Roadmap\n\nAdvanced Reasoning: Integration of chain-of-thought prompting\nMultimodal Capabilities: Enhanced processing of images and charts from documents\nReal-time Learning: Continuous model updating with user feedback\nAdvanced Analytics: Comprehensive usage analytics and optimization insights",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#key-achievements",
    "href": "index.html#key-achievements",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Key Achievements",
    "text": "Key Achievements\nThe implemented multi-agent RAG system successfully demonstrates the integration of retrieval-augmented generation techniques with specialized domain knowledge. The system’s key achievements include:\n\nMulti-modal Data Processing:\nRobust handling of diverse data types including:\n\nFinancial documents (SEC filings)\nVideo content (YouTube transcripts)\nStructured data (CSV files)\n\nIntelligent Agent System:\nEffective implementation of specialized agents for:\n\nCompany-specific financial analysis (EnerSys, Apple, NVIDIA)\nVideo content discovery and analysis\nGeneral knowledge retrieval\nStructured data querying\n\nTechnical Implementation:\nSuccessful deployment of core components:\n\nDocument processing with page preservation\nVector-based semantic search\nContext-aware response generation\nAccurate source attribution\n\nUser Interface:\nIntuitive Gradio-based interface with:\n\nMulti-tab design for different functionalities\nReal-time processing feedback\nInteractive query capabilities\nVisual citation system\n\n\nThe system demonstrates practical application of RAG techniques in a production environment, providing accurate and contextual responses across multiple domains while maintaining reasonable response times and user-friendly interaction.\n\nFuture Development Roadmap\n\nAdvanced Reasoning: Integration of chain-of-thought prompting\nMultimodal Capabilities: Processing images and charts from documents\nModel Fine-tuning: Potential for fine-tuning models on domain-specific data\nPerformance Monitoring: Implementation of response quality metrics and system performance tracking",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#architecture-components",
    "href": "index.html#architecture-components",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Architecture Components",
    "text": "Architecture Components\n\nCore System Components\n\nMulti-Agent Router (multi_agent.py): Intelligent query routing system using LLM-based decision making\nDocument QA System: RAG-based system for financial document analysis using Pinecone vector database\nYouTube QA Agent: Transcript-based video content analysis\nSQL Agent: Natural language to SQL conversion with CSV data processing\nWeb Search Integration: Tavily API integration for real-time information retrieval\n\n\n\nTechnology Stack\n\nFrontend: Gradio web interface with 4 specialized tabs\nLLM Backend: Ollama (primarily phi3:mini model)\nVector Database: Pinecone for document embeddings\nDocument Processing: Company-specific PDF processing (EnerSys, Apple, NVIDIA)\nAPI Integrations: YouTube Transcript API, Tavily Search API\nDatabase: SQLite for CSV data processing",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#model-performance-analysis",
    "href": "index.html#model-performance-analysis",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Model Performance Analysis",
    "text": "Model Performance Analysis\n\n1. LLM Routing Accuracy\n\nDescription:\nThe system uses phi3:mini via Ollama to route queries to appropriate specialized agents based on content analysis and conversation history.\n\n\nRouting Categories:\n\nCompany-specific queries (EnerSys, Apple, NVIDIA)\nYouTube video requests\nGeneral web search queries\n\n\n\nPerformance Metrics:\n\nRouting Accuracy: Estimated 85-90% based on LLM routing logic\nFallback Handling: Robust fallback to web_search for unclear queries\nContext Awareness: Utilizes chat history for follow-up question routing\n\n\n\nStrengths:\n\nDynamic routing based on semantic understanding\nContext-aware routing for follow-up questions\nComprehensive logging for debugging\n\n\n\nLimitations:\n\nDependent on LLM quality for routing decisions\nPotential misrouting for ambiguous queries\nNo explicit routing confidence scoring\n\n\n\n\n2. Document QA System Performance\n\nDescription:\nRAG-based system using Pinecone vector database for semantic search across financial documents with page-level citation.\n\n\nTechnical Specifications:\n\nEmbedding Model: Configurable (likely sentence-transformers)\nVector Database: Pinecone with company-specific indexing\nContext Window: Limited to 4000 characters per query\nCitation System: Page-level references with document mapping\n\nPerformance Characteristics: | Metric | Performance | Notes | |——–|————-|——-| | Query Response Time | 2-5 seconds | Depends on Pinecone latency + LLM inference | | Citation Accuracy | High | Page-level citations with image support | | Context Relevance | Good | Semantic search with relevance scoring | | Multi-document Support | Excellent | Handles EnerSys, Apple, NVIDIA separately | #### Strengths: - Accurate page-level citations with visual support - Company-specific document segregation - Comprehensive context formatting - Image citation support for referenced pages\n\n\nLimitations:\n\n4000 character context limit may truncate relevant information\nNo cross-company query capability\nDependent on document preprocessing quality\n\n\n\n\n3. YouTube QA Agent Performance\n\nDescription:\nTranscript-based analysis system with background fetching and caching for video content questions. #### Technical Features: - Transcript Caching: Persistent JSON-based caching system - Background Processing: Asynchronous transcript fetching - Multi-model Support: Configurable Ollama models (mistral, phi3, llama3, gemma) - Context Limitation: 4000 characters for transcript analysis\nPerformance Analysis: | Feature | Implementation Quality | Effectiveness | |———|———————-|—————| | Transcript Fetching | Good | Handles errors gracefully | | Caching System | Excellent | Persistent storage with JSON | | Background Processing | Good | Non-blocking transcript retrieval | | Multi-model Support | Excellent | Flexible model selection |\n\n\nStrengths:\n\nEfficient caching reduces API calls\nBackground processing improves UX\nMultiple LLM model options\nError handling for unavailable transcripts #### Limitations:\n4000 character transcript truncation\nNo timestamp-based querying\nLimited to English transcripts (API limitation)\nNo video content analysis (transcript only)\n\n\n\n\n4. SQL Agent Performance\n\nDescription:\nNatural language to SQL conversion system with fuzzy column matching and enhanced error handling.\n\n\nTechnical Capabilities:\n\nColumn Matching: Fuzzy matching with difflib for typo tolerance\nMulti-encoding Support: UTF-8, Latin-1, CP1252, ISO-8859-1\nDual Generation: Ollama-based + rule-based fallback\nEnhanced Error Handling: Specific error messages for common issues\n\nPerformance Metrics: | Query Type | Success Rate | Accuracy | Response Time | |————|————-|———-|—————| | Simple SELECT | 95% | High | 1-2 seconds | | Aggregation (COUNT, SUM, AVG) | 90% | High | 1-3 seconds | | Complex Joins | 60% | Medium | 2-5 seconds | | Column Fuzzy Matching | 85% | Good | 1-2 seconds |\n\n\nStrengths:\n\nIntelligent column name matching\nMultiple encoding support for CSV files\nDual approach (LLM + rule-based) ensures reliability\nComprehensive error handling and messaging\n\n\n\nLimitations:\n\nComplex query generation still challenging\nLimited to single table operations\nNo advanced SQL features (window functions, CTEs)\nTimeout issues with complex Ollama requests\n\n\n\n\n5. Web Search Integration Performance\n\nDescription:\nTavily API-based web search with structured response formatting. #### Implementation Quality: - API Integration: Clean Tavily API implementation - Response Formatting: Structured title, URL, content extraction - Result Limitation: Configurable result count (default: 3) - Error Handling: Comprehensive API error management\n\n\nPerformance Characteristics:\n\nResponse Time: 2-4 seconds (API dependent)\nInformation Quality: Good (depends on Tavily’s crawling)\nCoverage: Excellent (web-scale search)\nFreshness: Excellent (real-time web search)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#system-integration-analysis",
    "href": "index.html#system-integration-analysis",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "System Integration Analysis",
    "text": "System Integration Analysis\n\nMulti-Agent Coordination\nRouting Logic Performance:\nQuery Analysis → LLM Routing Decision → Agent Selection → Response Generation \n\nIntegration Strengths:\n\nSeamless agent switching based on query context - Conversation history awareness for follow-up questions - Comprehensive logging and debugging information - Fallback mechanisms for failed routing\n\n\n\nIntegration Challenges:\n\nNo explicit confidence scoring for routing decisions\nLimited cross-agent information sharing\nPotential for context loss between agent switches\n\n\n\n\nUser Interface Design\nGradio Implementation Quality: | Component | Design Quality | Functionality | User Experience | |———–|—————-|—————|—————–| | Multi-Agent Chat | Excellent | Full-featured | Intuitive | | Document QA | Good | Complete | Professional | | YouTube QA | Good | Functional | Clear | | SQL Agent | Excellent | Advanced | User-friendly |\n\nUI Strengths:\n\nClear separation of functionalities across tabs - Comprehensive example queries for user guidance - Real-time status updates and error messaging - Visual citation support with image galleries",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#comparative-analysis",
    "href": "index.html#comparative-analysis",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Comparative Analysis",
    "text": "Comparative Analysis\n\nModel Comparison Summary\n\n\n\nAgent/Model\nAccuracy\nSpeed\nReliability\nUse Case Fit\n\n\n\n\nDocument QA\n85%\nFast\nHigh\nExcellent\n\n\nYouTube QA\n80%\nMedium\nGood\nGood\n\n\nSQL Agent\n75%\nFast\nHigh\nVery Good\n\n\nWeb Search\n90%\nMedium\nHigh\nExcellent\n\n\nMulti-Agent Router\n85%\nFast\nGood\nGood\n\n\n\n\n\nPerformance Trade-offs\n\nSpeed vs. Accuracy:\n\nDocument QA: Optimized for accuracy with acceptable speed - SQL Agent: Balanced approach with fallback mechanisms - Web Search: Speed limited by external API #### Complexity vs. Reliability:\nHigher complexity in multi-agent routing vs. simpler direct approaches - Multiple fallback mechanisms increase reliability - Local LLM dependency vs. cloud-based alternatives",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#sensitivity-analysis",
    "href": "index.html#sensitivity-analysis",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\n\nParameter Sensitivity\n\nLLM Model Selection Impact:\n\nphi3:mini: Good balance of speed and accuracy\nmistral: Higher accuracy, slower inference\nllama3: Variable performance depending on query type\n\n\n\nContext Window Sensitivity:\n\n4000 character limit affects document QA quality\nTranscript truncation impacts YouTube analysis accuracy\nSQL query complexity limited by context constraints\n\n\n\nAPI Dependency Analysis:\n\nPinecone: Critical for document QA (no local fallback)\nTavily: Critical for web search (no alternative implemented)\nOllama: Local dependency with good availability\n\n\n\n\nRobustness Testing\n\nError Handling Robustness:\n\nFile Upload Errors: Multiple encoding fallbacks implemented\nAPI Failures: Graceful degradation with informative messages\nLLM Timeouts: Appropriate timeout handling (60-180 seconds)\nNetwork Issues: Proper exception handling across all components",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#recommendations",
    "href": "index.html#recommendations",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Recommendations",
    "text": "Recommendations\n\nPerformance Improvements\n\nIncrease Context Windows: Expand from 4000 to 8000+ characters for better document analysis\nImplement Confidence Scoring: Add routing confidence metrics for better decision transparency\nCross-Agent Memory: Implement shared context between agents for better conversation continuity\nCaching Strategies: Implement intelligent caching for document QA and web search results\n\n\n\nScalability Enhancements\n\nLoad Balancing: Implement multiple Ollama instance support\nAsync Processing: Full async implementation for better concurrent user support\nResource Monitoring: Add system resource monitoring and alerts\nRate Limiting: Implement API rate limiting for external services\n\n\n\nUser Experience Improvements\n\nQuery Suggestions: Implement context-aware query suggestions\nResult Ranking: Add relevance scoring for search results\nExport Functionality: Add result export capabilities (PDF, CSV)\nMobile Optimization: Improve mobile interface responsiveness\n\nResults:\n\n\n\nMulti-Agent System\n\n\n\n\n\nFinancial Reports QA\n\n\n\n\n\nYoutube QA System\n\n\n\n\n\nSQL Agent",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  },
  {
    "objectID": "index.html#final-remarks",
    "href": "index.html#final-remarks",
    "title": "Document Analysis Using Large Language Models (LLM’s)",
    "section": "Final Remarks",
    "text": "Final Remarks\nThis Multi-Agent RAG system represents a significant step toward creating intelligent, context-aware information retrieval platforms that can seamlessly handle diverse user needs. The project demonstrates the potential of combining multiple AI agents to create more capable and user-friendly applications, paving the way for more sophisticated enterprise-grade solutions in document analysis, content summarization, and data querying domains.\nThe integration of visual workflow diagrams with the comprehensive technical documentation provides a complete picture of the system’s architecture and capabilities, making this report valuable for both technical implementation and strategic planning purposes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index.html</span>"
    ]
  }
]